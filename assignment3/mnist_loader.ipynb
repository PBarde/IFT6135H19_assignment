{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import utils\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn.modules import upsampling\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset_location, batch_size):\n",
    "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
    "    # start processing\n",
    "    def lines_to_np_array(lines):\n",
    "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
    "    splitdata = []\n",
    "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
    "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
    "        filepath = os.path.join(dataset_location, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            utils.download_url(URL + filename, dataset_location, filename, None)\n",
    "        with open(filepath) as f:\n",
    "            lines = f.readlines()\n",
    "        x = lines_to_np_array(lines).astype('float32')\n",
    "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
    "        # pytorch data loader\n",
    "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
    "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
    "        splitdata.append(dataset_loader)\n",
    "    return splitdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_data_loader(\"binarized_mnist\", 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for x in train_loader:\n",
    "    plt.imshow(x[0, 0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vae  # needed to allow the reload\n",
    "import importlib\n",
    "importlib.reload(vae)  # forces a reloading of the module (because jupyter notebook will not reload it after it has been modified)\n",
    "from vae import VAE\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # ELBO: L(θ, φ; x) = -E_z~q_φ[log p_θ(x|z)] + D_KL(q_φ(z|x)||p(z))\n",
    "    # reconstruction loss + regularizer (forcing the encoder's output to stay close to a standard Normal distribution)\n",
    "\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train_vae(epoch, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "    \n",
    "def test_vae(epoch, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 559.434448\n",
      "Train Epoch: 0 [640/50000 (1%)]\tLoss: 508.527374\n",
      "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 398.799255\n",
      "Train Epoch: 0 [1920/50000 (4%)]\tLoss: 371.047791\n",
      "Train Epoch: 0 [2560/50000 (5%)]\tLoss: 321.389526\n",
      "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 280.178375\n",
      "Train Epoch: 0 [3840/50000 (8%)]\tLoss: 251.604797\n",
      "Train Epoch: 0 [4480/50000 (9%)]\tLoss: 230.729111\n",
      "Train Epoch: 0 [5120/50000 (10%)]\tLoss: 224.704010\n",
      "Train Epoch: 0 [5760/50000 (12%)]\tLoss: 214.979050\n",
      "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 213.663879\n",
      "Train Epoch: 0 [7040/50000 (14%)]\tLoss: 207.589935\n",
      "Train Epoch: 0 [7680/50000 (15%)]\tLoss: 194.134140\n",
      "Train Epoch: 0 [8320/50000 (17%)]\tLoss: 201.056076\n",
      "Train Epoch: 0 [8960/50000 (18%)]\tLoss: 199.057755\n",
      "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 201.255661\n",
      "Train Epoch: 0 [10240/50000 (20%)]\tLoss: 204.563583\n",
      "Train Epoch: 0 [10880/50000 (22%)]\tLoss: 195.626221\n",
      "Train Epoch: 0 [11520/50000 (23%)]\tLoss: 185.445801\n",
      "Train Epoch: 0 [12160/50000 (24%)]\tLoss: 190.839874\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 188.189240\n",
      "Train Epoch: 0 [13440/50000 (27%)]\tLoss: 184.157776\n",
      "Train Epoch: 0 [14080/50000 (28%)]\tLoss: 178.433167\n",
      "Train Epoch: 0 [14720/50000 (29%)]\tLoss: 181.616486\n",
      "Train Epoch: 0 [15360/50000 (31%)]\tLoss: 177.400528\n",
      "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 176.429657\n",
      "Train Epoch: 0 [16640/50000 (33%)]\tLoss: 170.165359\n",
      "Train Epoch: 0 [17280/50000 (35%)]\tLoss: 180.045288\n",
      "Train Epoch: 0 [17920/50000 (36%)]\tLoss: 170.683945\n",
      "Train Epoch: 0 [18560/50000 (37%)]\tLoss: 166.931900\n",
      "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 167.564117\n",
      "Train Epoch: 0 [19840/50000 (40%)]\tLoss: 163.927338\n",
      "Train Epoch: 0 [20480/50000 (41%)]\tLoss: 174.073120\n",
      "Train Epoch: 0 [21120/50000 (42%)]\tLoss: 162.595139\n",
      "Train Epoch: 0 [21760/50000 (43%)]\tLoss: 172.942535\n",
      "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 164.120850\n",
      "Train Epoch: 0 [23040/50000 (46%)]\tLoss: 164.798813\n",
      "Train Epoch: 0 [23680/50000 (47%)]\tLoss: 159.166473\n",
      "Train Epoch: 0 [24320/50000 (49%)]\tLoss: 157.822800\n",
      "Train Epoch: 0 [24960/50000 (50%)]\tLoss: 156.675751\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 152.897232\n",
      "Train Epoch: 0 [26240/50000 (52%)]\tLoss: 162.505753\n",
      "Train Epoch: 0 [26880/50000 (54%)]\tLoss: 165.721664\n",
      "Train Epoch: 0 [27520/50000 (55%)]\tLoss: 168.097885\n",
      "Train Epoch: 0 [28160/50000 (56%)]\tLoss: 155.809982\n",
      "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 158.114273\n",
      "Train Epoch: 0 [29440/50000 (59%)]\tLoss: 159.003494\n",
      "Train Epoch: 0 [30080/50000 (60%)]\tLoss: 152.244949\n",
      "Train Epoch: 0 [30720/50000 (61%)]\tLoss: 154.119949\n",
      "Train Epoch: 0 [31360/50000 (63%)]\tLoss: 149.810120\n",
      "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 165.655212\n",
      "Train Epoch: 0 [32640/50000 (65%)]\tLoss: 156.140732\n",
      "Train Epoch: 0 [33280/50000 (66%)]\tLoss: 158.752151\n",
      "Train Epoch: 0 [33920/50000 (68%)]\tLoss: 149.376801\n",
      "Train Epoch: 0 [34560/50000 (69%)]\tLoss: 152.632874\n",
      "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 148.446213\n",
      "Train Epoch: 0 [35840/50000 (72%)]\tLoss: 146.827042\n",
      "Train Epoch: 0 [36480/50000 (73%)]\tLoss: 153.388000\n",
      "Train Epoch: 0 [37120/50000 (74%)]\tLoss: 152.885406\n",
      "Train Epoch: 0 [37760/50000 (75%)]\tLoss: 155.647812\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 141.993195\n",
      "Train Epoch: 0 [39040/50000 (78%)]\tLoss: 145.029633\n",
      "Train Epoch: 0 [39680/50000 (79%)]\tLoss: 146.872314\n",
      "Train Epoch: 0 [40320/50000 (81%)]\tLoss: 146.644104\n",
      "Train Epoch: 0 [40960/50000 (82%)]\tLoss: 145.170212\n",
      "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 138.249939\n",
      "Train Epoch: 0 [42240/50000 (84%)]\tLoss: 141.384659\n",
      "Train Epoch: 0 [42880/50000 (86%)]\tLoss: 152.358475\n",
      "Train Epoch: 0 [43520/50000 (87%)]\tLoss: 144.989624\n",
      "Train Epoch: 0 [44160/50000 (88%)]\tLoss: 143.157410\n",
      "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 152.276672\n",
      "Train Epoch: 0 [45440/50000 (91%)]\tLoss: 148.469757\n",
      "Train Epoch: 0 [46080/50000 (92%)]\tLoss: 143.123383\n",
      "Train Epoch: 0 [46720/50000 (93%)]\tLoss: 146.920212\n",
      "Train Epoch: 0 [47360/50000 (95%)]\tLoss: 134.777252\n",
      "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 133.021622\n",
      "Train Epoch: 0 [48640/50000 (97%)]\tLoss: 135.051071\n",
      "Train Epoch: 0 [49280/50000 (98%)]\tLoss: 129.328186\n",
      "Train Epoch: 0 [49920/50000 (100%)]\tLoss: 144.090485\n",
      "====> Epoch: 0 Average loss: 182.8779\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 134.643143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raphael\\Miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 145.726807\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 140.411819\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 128.488907\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 135.772278\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 141.582932\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 136.952225\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 139.585571\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 134.790436\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 135.232147\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 139.159958\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 138.986389\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 136.350006\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 131.318466\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 131.559738\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 131.898743\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 133.782898\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 130.530609\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 134.036987\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 128.453674\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 135.436935\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 123.955025\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 125.157806\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 128.204163\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 129.205444\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 126.915466\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 124.147797\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 135.786743\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 130.955032\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 130.933075\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 130.115540\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 127.869904\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 125.271149\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 130.802719\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 134.489349\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 128.604401\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 126.112381\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 128.731339\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 120.513077\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 123.920654\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 114.847557\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 121.364273\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 126.234909\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 126.097191\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 121.569077\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 121.328606\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 119.356216\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 120.618134\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 113.729797\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 124.640831\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 124.118042\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 126.044083\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 124.451752\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 116.560234\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 121.556770\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 128.127930\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 124.101456\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 120.807381\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 127.394051\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 116.672348\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 125.350082\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 123.252098\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 118.451912\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 115.597054\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 118.644943\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 119.387634\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 110.887451\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 120.745316\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 115.857788\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 121.683838\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 112.364105\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 123.969490\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 118.026360\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 122.565628\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 113.862808\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 122.141548\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 117.085831\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 121.336502\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 117.470184\n",
      "====> Epoch: 1 Average loss: 126.0733\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 118.162476\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 117.042877\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 118.824387\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 113.184135\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 119.778687\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 118.913963\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 113.558258\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 112.490547\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 118.352676\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 119.433922\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 115.939598\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 115.406067\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 113.154175\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 110.133911\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 112.717484\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 119.697021\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 116.190598\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 115.978485\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 113.775650\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 113.650780\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 109.937119\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 116.381996\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 104.626778\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 110.683731\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 111.034760\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 119.372604\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 112.952522\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 108.814598\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 114.098740\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 103.468987\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 110.139687\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 117.651619\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 109.632462\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 110.323257\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 112.679771\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 116.774185\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 120.158646\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 118.424530\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 113.141525\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 120.706619\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 115.781044\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 106.010406\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 114.478325\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 113.460045\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 104.997116\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 115.323738\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 111.460426\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 114.785919\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 107.803879\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 108.323151\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 106.438461\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 108.958344\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 112.629456\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 106.929298\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 105.250702\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 108.318283\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 114.810188\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 120.584351\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 104.831947\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 112.433289\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 114.390594\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 109.144470\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 111.818451\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 113.172928\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 108.901634\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 102.742355\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 116.441833\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 112.230278\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 110.458054\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 115.065201\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 110.190796\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 112.492104\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 111.851814\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 105.307373\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 109.345894\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 111.751785\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 112.154877\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 110.174965\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 108.440323\n",
      "====> Epoch: 2 Average loss: 112.4561\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 102.194855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 106.514832\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 115.956268\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 108.481026\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 103.077972\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 109.469719\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 105.841202\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 110.401886\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 102.599632\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 111.020531\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 109.728020\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 110.761459\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 106.897430\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 102.509895\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 109.090591\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 117.557655\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 104.690552\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 110.728661\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 106.563171\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 106.082932\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 107.236877\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 108.450012\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 107.084930\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 109.591354\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 109.837723\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 110.711739\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 109.092102\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 103.906433\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 104.084549\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 106.764297\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 108.276947\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 104.722694\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 106.250481\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 104.307556\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 106.119629\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 105.908867\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 109.408203\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 99.634476\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 106.126999\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 109.370354\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 107.878548\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 106.541855\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 105.934464\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 108.646881\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 106.680817\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 106.751526\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 102.377930\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 100.780594\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 105.355782\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 109.494324\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 103.577301\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 112.626740\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 105.866852\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 110.181236\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 102.668823\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 107.404640\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 100.681816\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 114.310379\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 110.390213\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 103.509247\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 109.032936\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 107.772812\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 107.943596\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 115.080101\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 103.853188\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 102.174263\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 103.737350\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 116.387726\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 98.875992\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 105.311646\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 101.318779\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 108.108505\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 103.371475\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 104.625168\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 106.071655\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 110.690140\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 102.265747\n",
      "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 101.779503\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 101.560478\n",
      "====> Epoch: 3 Average loss: 106.9577\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 104.526184\n",
      "Train Epoch: 4 [640/50000 (1%)]\tLoss: 107.171494\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 103.933456\n",
      "Train Epoch: 4 [1920/50000 (4%)]\tLoss: 105.961441\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 104.551277\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 107.268761\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 112.827576\n",
      "Train Epoch: 4 [4480/50000 (9%)]\tLoss: 107.296127\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 103.388802\n",
      "Train Epoch: 4 [5760/50000 (12%)]\tLoss: 108.964081\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 102.898964\n",
      "Train Epoch: 4 [7040/50000 (14%)]\tLoss: 109.064316\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 104.833023\n",
      "Train Epoch: 4 [8320/50000 (17%)]\tLoss: 101.675095\n",
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 106.408676\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 105.202499\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 97.424721\n",
      "Train Epoch: 4 [10880/50000 (22%)]\tLoss: 105.504196\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 102.948502\n",
      "Train Epoch: 4 [12160/50000 (24%)]\tLoss: 109.270416\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 97.847855\n",
      "Train Epoch: 4 [13440/50000 (27%)]\tLoss: 108.908173\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 105.094620\n",
      "Train Epoch: 4 [14720/50000 (29%)]\tLoss: 106.024841\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 103.709305\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 100.090202\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 103.938690\n",
      "Train Epoch: 4 [17280/50000 (35%)]\tLoss: 102.503220\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 104.152283\n",
      "Train Epoch: 4 [18560/50000 (37%)]\tLoss: 102.472855\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 103.403221\n",
      "Train Epoch: 4 [19840/50000 (40%)]\tLoss: 102.343742\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 102.330803\n",
      "Train Epoch: 4 [21120/50000 (42%)]\tLoss: 101.735283\n",
      "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 109.047356\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 102.138840\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 101.798683\n",
      "Train Epoch: 4 [23680/50000 (47%)]\tLoss: 100.501862\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 107.233200\n",
      "Train Epoch: 4 [24960/50000 (50%)]\tLoss: 99.631721\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 101.716965\n",
      "Train Epoch: 4 [26240/50000 (52%)]\tLoss: 98.988007\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 106.828278\n",
      "Train Epoch: 4 [27520/50000 (55%)]\tLoss: 104.456383\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 103.597313\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 110.542580\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 108.151749\n",
      "Train Epoch: 4 [30080/50000 (60%)]\tLoss: 100.832733\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 101.167908\n",
      "Train Epoch: 4 [31360/50000 (63%)]\tLoss: 104.925797\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 103.117279\n",
      "Train Epoch: 4 [32640/50000 (65%)]\tLoss: 109.309731\n",
      "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 104.152748\n",
      "Train Epoch: 4 [33920/50000 (68%)]\tLoss: 96.352081\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 105.009209\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 99.303650\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 105.587296\n",
      "Train Epoch: 4 [36480/50000 (73%)]\tLoss: 104.879478\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 106.096947\n",
      "Train Epoch: 4 [37760/50000 (75%)]\tLoss: 103.595749\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 102.922028\n",
      "Train Epoch: 4 [39040/50000 (78%)]\tLoss: 102.738007\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 107.376671\n",
      "Train Epoch: 4 [40320/50000 (81%)]\tLoss: 102.147034\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 105.058464\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 102.093834\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 102.409348\n",
      "Train Epoch: 4 [42880/50000 (86%)]\tLoss: 106.000031\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 107.756653\n",
      "Train Epoch: 4 [44160/50000 (88%)]\tLoss: 102.093399\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 101.465164\n",
      "Train Epoch: 4 [45440/50000 (91%)]\tLoss: 98.960938\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 102.835228\n",
      "Train Epoch: 4 [46720/50000 (93%)]\tLoss: 107.653015\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 104.810135\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 107.096832\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 98.679474\n",
      "Train Epoch: 4 [49280/50000 (98%)]\tLoss: 99.315994\n",
      "Train Epoch: 4 [49920/50000 (100%)]\tLoss: 97.205673\n",
      "====> Epoch: 4 Average loss: 103.9403\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 106.619865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [640/50000 (1%)]\tLoss: 100.106125\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 102.079475\n",
      "Train Epoch: 5 [1920/50000 (4%)]\tLoss: 100.530128\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 100.938896\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 112.991562\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 102.288094\n",
      "Train Epoch: 5 [4480/50000 (9%)]\tLoss: 95.757401\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 102.021820\n",
      "Train Epoch: 5 [5760/50000 (12%)]\tLoss: 103.923370\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 100.506889\n",
      "Train Epoch: 5 [7040/50000 (14%)]\tLoss: 104.086754\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 100.122795\n",
      "Train Epoch: 5 [8320/50000 (17%)]\tLoss: 97.753586\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 103.656830\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 104.662933\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 102.263565\n",
      "Train Epoch: 5 [10880/50000 (22%)]\tLoss: 100.815857\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 99.858749\n",
      "Train Epoch: 5 [12160/50000 (24%)]\tLoss: 106.833488\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 100.906631\n",
      "Train Epoch: 5 [13440/50000 (27%)]\tLoss: 106.336456\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 92.762375\n",
      "Train Epoch: 5 [14720/50000 (29%)]\tLoss: 104.714508\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 95.061432\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 98.793442\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 98.598015\n",
      "Train Epoch: 5 [17280/50000 (35%)]\tLoss: 104.398094\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 106.897125\n",
      "Train Epoch: 5 [18560/50000 (37%)]\tLoss: 103.315895\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 107.207886\n",
      "Train Epoch: 5 [19840/50000 (40%)]\tLoss: 101.446663\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 100.376373\n",
      "Train Epoch: 5 [21120/50000 (42%)]\tLoss: 99.315155\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 97.588127\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 100.764816\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 102.271942\n",
      "Train Epoch: 5 [23680/50000 (47%)]\tLoss: 100.834503\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 101.075623\n",
      "Train Epoch: 5 [24960/50000 (50%)]\tLoss: 97.102386\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 101.387939\n",
      "Train Epoch: 5 [26240/50000 (52%)]\tLoss: 94.955536\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 100.408394\n",
      "Train Epoch: 5 [27520/50000 (55%)]\tLoss: 95.362167\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 100.985382\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 97.321716\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 107.638672\n",
      "Train Epoch: 5 [30080/50000 (60%)]\tLoss: 104.348526\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 102.304062\n",
      "Train Epoch: 5 [31360/50000 (63%)]\tLoss: 100.187538\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 108.068039\n",
      "Train Epoch: 5 [32640/50000 (65%)]\tLoss: 96.276764\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 104.912636\n",
      "Train Epoch: 5 [33920/50000 (68%)]\tLoss: 107.831200\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 110.375046\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 102.939285\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 95.902634\n",
      "Train Epoch: 5 [36480/50000 (73%)]\tLoss: 102.430313\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 100.429306\n",
      "Train Epoch: 5 [37760/50000 (75%)]\tLoss: 94.290565\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 103.367516\n",
      "Train Epoch: 5 [39040/50000 (78%)]\tLoss: 104.454681\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 107.300980\n",
      "Train Epoch: 5 [40320/50000 (81%)]\tLoss: 99.829063\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 101.241348\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 101.568535\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 99.115570\n",
      "Train Epoch: 5 [42880/50000 (86%)]\tLoss: 105.011139\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 98.034157\n",
      "Train Epoch: 5 [44160/50000 (88%)]\tLoss: 96.113861\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 97.661591\n",
      "Train Epoch: 5 [45440/50000 (91%)]\tLoss: 97.053154\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 100.130424\n",
      "Train Epoch: 5 [46720/50000 (93%)]\tLoss: 97.903290\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 101.336594\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 103.344925\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 101.199654\n",
      "Train Epoch: 5 [49280/50000 (98%)]\tLoss: 98.094055\n",
      "Train Epoch: 5 [49920/50000 (100%)]\tLoss: 104.105453\n",
      "====> Epoch: 5 Average loss: 101.8270\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 97.935120\n",
      "Train Epoch: 6 [640/50000 (1%)]\tLoss: 99.565048\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 96.056000\n",
      "Train Epoch: 6 [1920/50000 (4%)]\tLoss: 105.830017\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 100.021980\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 97.369354\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 102.424881\n",
      "Train Epoch: 6 [4480/50000 (9%)]\tLoss: 99.347130\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 102.242218\n",
      "Train Epoch: 6 [5760/50000 (12%)]\tLoss: 105.419685\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 97.042770\n",
      "Train Epoch: 6 [7040/50000 (14%)]\tLoss: 103.079735\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 97.737839\n",
      "Train Epoch: 6 [8320/50000 (17%)]\tLoss: 96.891815\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 101.380959\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 96.131134\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 87.762878\n",
      "Train Epoch: 6 [10880/50000 (22%)]\tLoss: 96.861145\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 104.999855\n",
      "Train Epoch: 6 [12160/50000 (24%)]\tLoss: 96.503769\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 103.901138\n",
      "Train Epoch: 6 [13440/50000 (27%)]\tLoss: 103.754410\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 99.814896\n",
      "Train Epoch: 6 [14720/50000 (29%)]\tLoss: 100.865013\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 99.658073\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 100.043022\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 101.814270\n",
      "Train Epoch: 6 [17280/50000 (35%)]\tLoss: 104.365158\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 102.482414\n",
      "Train Epoch: 6 [18560/50000 (37%)]\tLoss: 102.549301\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 103.357330\n",
      "Train Epoch: 6 [19840/50000 (40%)]\tLoss: 99.676193\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 101.277176\n",
      "Train Epoch: 6 [21120/50000 (42%)]\tLoss: 97.732758\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 95.426834\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 101.147980\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 100.623695\n",
      "Train Epoch: 6 [23680/50000 (47%)]\tLoss: 97.139320\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 99.129593\n",
      "Train Epoch: 6 [24960/50000 (50%)]\tLoss: 97.591919\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 95.776993\n",
      "Train Epoch: 6 [26240/50000 (52%)]\tLoss: 108.812805\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 101.021667\n",
      "Train Epoch: 6 [27520/50000 (55%)]\tLoss: 103.837311\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 95.259247\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 107.002640\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 103.084511\n",
      "Train Epoch: 6 [30080/50000 (60%)]\tLoss: 99.756393\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 100.913589\n",
      "Train Epoch: 6 [31360/50000 (63%)]\tLoss: 97.720612\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 99.192474\n",
      "Train Epoch: 6 [32640/50000 (65%)]\tLoss: 96.881378\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 96.614456\n",
      "Train Epoch: 6 [33920/50000 (68%)]\tLoss: 101.584915\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 95.881195\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 99.663605\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 102.481262\n",
      "Train Epoch: 6 [36480/50000 (73%)]\tLoss: 105.282425\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 100.693718\n",
      "Train Epoch: 6 [37760/50000 (75%)]\tLoss: 98.309326\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 99.208015\n",
      "Train Epoch: 6 [39040/50000 (78%)]\tLoss: 103.985054\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 101.876144\n",
      "Train Epoch: 6 [40320/50000 (81%)]\tLoss: 96.895088\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 97.248734\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 93.937592\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 101.211426\n",
      "Train Epoch: 6 [42880/50000 (86%)]\tLoss: 98.291763\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 102.274269\n",
      "Train Epoch: 6 [44160/50000 (88%)]\tLoss: 102.870743\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 105.414291\n",
      "Train Epoch: 6 [45440/50000 (91%)]\tLoss: 100.328094\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 96.258652\n",
      "Train Epoch: 6 [46720/50000 (93%)]\tLoss: 101.798492\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 100.735588\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 99.125244\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 102.292313\n",
      "Train Epoch: 6 [49280/50000 (98%)]\tLoss: 99.355171\n",
      "Train Epoch: 6 [49920/50000 (100%)]\tLoss: 98.200905\n",
      "====> Epoch: 6 Average loss: 100.3307\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 97.175980\n",
      "Train Epoch: 7 [640/50000 (1%)]\tLoss: 95.659805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 106.877869\n",
      "Train Epoch: 7 [1920/50000 (4%)]\tLoss: 100.216469\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 96.693054\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 97.057747\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 97.973465\n",
      "Train Epoch: 7 [4480/50000 (9%)]\tLoss: 105.769653\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 102.813362\n",
      "Train Epoch: 7 [5760/50000 (12%)]\tLoss: 98.613365\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 95.740273\n",
      "Train Epoch: 7 [7040/50000 (14%)]\tLoss: 103.256516\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 99.303970\n",
      "Train Epoch: 7 [8320/50000 (17%)]\tLoss: 99.672310\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 101.108894\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 96.866425\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 95.272057\n",
      "Train Epoch: 7 [10880/50000 (22%)]\tLoss: 99.493668\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 102.585831\n",
      "Train Epoch: 7 [12160/50000 (24%)]\tLoss: 97.474197\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 96.054863\n",
      "Train Epoch: 7 [13440/50000 (27%)]\tLoss: 101.566628\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 103.611496\n",
      "Train Epoch: 7 [14720/50000 (29%)]\tLoss: 94.315948\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 97.957611\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 102.817474\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 98.463913\n",
      "Train Epoch: 7 [17280/50000 (35%)]\tLoss: 92.397842\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 106.171356\n",
      "Train Epoch: 7 [18560/50000 (37%)]\tLoss: 94.253723\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 100.480965\n",
      "Train Epoch: 7 [19840/50000 (40%)]\tLoss: 95.638947\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 99.114563\n",
      "Train Epoch: 7 [21120/50000 (42%)]\tLoss: 98.815239\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 102.005508\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 98.270065\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 98.683495\n",
      "Train Epoch: 7 [23680/50000 (47%)]\tLoss: 96.220459\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 98.749069\n",
      "Train Epoch: 7 [24960/50000 (50%)]\tLoss: 96.106262\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 100.011292\n",
      "Train Epoch: 7 [26240/50000 (52%)]\tLoss: 100.732712\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 101.962906\n",
      "Train Epoch: 7 [27520/50000 (55%)]\tLoss: 99.795074\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 96.595894\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 100.050774\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 102.134125\n",
      "Train Epoch: 7 [30080/50000 (60%)]\tLoss: 101.086708\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 93.763138\n",
      "Train Epoch: 7 [31360/50000 (63%)]\tLoss: 100.208321\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 98.172104\n",
      "Train Epoch: 7 [32640/50000 (65%)]\tLoss: 96.310066\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 94.140610\n",
      "Train Epoch: 7 [33920/50000 (68%)]\tLoss: 97.743187\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 101.774605\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 101.367821\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 104.321770\n",
      "Train Epoch: 7 [36480/50000 (73%)]\tLoss: 92.268951\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 101.850861\n",
      "Train Epoch: 7 [37760/50000 (75%)]\tLoss: 99.318108\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    train_vae(epoch, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
